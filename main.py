"""
Auteur : MEZRIGUI Chihab üë®‚Äçüíª
Date : 03/06/2024 üìÖ

Ce Code utilise diverses biblioth√®ques pour cr√©er des fonctions en Python permettant 
d'interagir avec l'API Google Sheets via Google Cloud Platform, ainsi qu'√† effectuer 
une analyse n-gram sur les donn√©es collect√©es.

"""

import re
from google.oauth2.service_account import Credentials
import gspread
import pandas as pd
from collections import Counter
from nltk.corpus import stopwords
from nltk.util import ngrams
from nltk.tokenize import word_tokenize
import matplotlib.pyplot as plt
from wordcloud import WordCloud


""" 
   Fonction 1 : Connection √† l‚ÄôAPI Google Sheets 

"""

# Acc√®s au service Google Sheet API
def connexion_to_googlesheets(json_keyfile):
    try:
        SCOPES = ["https://www.googleapis.com/auth/spreadsheets",
                  "https://www.googleapis.com/auth/drive"]
        
        credentials = Credentials.from_service_account_file(json_keyfile, scopes=SCOPES)
        user = gspread.authorize(credentials)
        print("Connection √† l'API Google Sheets r√©ussie.")
        return user
    except Exception as e:
        print(f"Erreur lors de la connection: {e}")
        return None



""" 
   Fonction 2 : Analyse n-gram 
"""

# Fonction pour nettoyer et pr√©traiter les donn√©es textuelles
def clean_text(text):
    # Convertir le texte en minuscules
    text = text.lower()
    # Remplacer les lettres accentu√©es par des lettres normales
    text = re.sub(r'[√¢√£√§√•]', 'a', text)
    text = re.sub(r'[√ß]', 'c', text)
    text = re.sub(r'[√®√©√™√´]', 'e', text)
    text = re.sub(r'[√¨√≠√Æ√Ø]', 'i', text)
    text = re.sub(r'[√≤√≥√¥√µ√∂]', 'o', text)
    text = re.sub(r'[√π√∫√ª√º]', 'u', text)
    text = re.sub(r'[√ø]', 'y', text)

    # Supprimer les caract√®res sp√©ciaux et les chiffres
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Tokeniser le texte
    words = word_tokenize(text)
    # Supprimer les mots vides (stop words)
    stop_words = set(stopwords.words('french'))
    words = [
        word for word in words 
             if word not in stop_words
    ]
    return words


# G√©n√©rer les n-grams
def generate_ngrams(text, n):
    # On fait un appel pour la fonction clean_text
    words = clean_text(text)
    n_grams = ngrams(words, n)
    return [' '.join(grams) for grams in n_grams]


# Analyser la fr√©quence des n-grams
def analyze_ngrams(texts, n):
    all_ngrams = []
    for text in texts:
        all_ngrams.extend(generate_ngrams(text, n))
    n_gram_counts = Counter(all_ngrams)
    return n_gram_counts.most_common() # tri√©s par leur fr√©quence



# Charger les donn√©es textuelles depuis le fichier CSV
csv_file_path = r'data\data_science_phrases.csv'
df = pd.read_csv(csv_file_path)

# On prend la colonne 'texte' qui contient les donn√©es textuelles .
texts = df['texte'].dropna().tolist()

# D√©terminer la longueur maximale des textes
max_length = max(len(clean_text(text)) for text in texts)
print("longueur",max_length)

# Dictionnaire pour stocker les r√©sultats des n-grams de diff√©rentes tailles
ngrams_results = {}

# G√©n√©rer et analyser des n-grams automatiquement jusqu'√† la longueur maximale des textes
for n in range(1, max_length + 1):
    ngrams_results[n] = analyze_ngrams(texts, n)
    # print(f"{n}-grams les plus fr√©quents:", ngrams_results[n])

# Sauvegarder les r√©sultats dans des fichiers CSV
for n, ngrams in ngrams_results.items():
    ngrams_df = pd.DataFrame(ngrams, columns=[f'{n}-gram', 'frequency'])
    ngrams_df.to_csv(f'data/{n}grams_frequency.csv', index=False)

print("Les r√©sultats ont √©t√© sauvegard√©s dans des fichiers CSV")




""" 
  Un + üòä =>  Partie : VISUALISATION DES DONNEES 

"""

# Fonction pour la visualisation des donn√©es de n_grams et leurs fr√©quence sous forme d'un nuage de mots

def vis_nuage_mots(ngrams_results, n):
    # Pr√©parer les n_grams et leurs fr√©quences en les Convertir en un dictionnaire
    ngrams_dict = dict(ngrams_results[n])
    # print("afficher dictionnaire",ngrams_dict)
        
    # Cr√©ation du nuage de mots
    wordcloud = WordCloud(width=900, height=400, background_color='white').generate_from_frequencies(ngrams_dict)
    # Affichage
    plt.figure(figsize=(10, 6))
    plt.imshow(wordcloud, interpolation='bilinear')    
    plt.axis('off')
    plt.title(f'Nuage de mots des {n}-grams les plus fr√©quents')
    plt.show()

# On applique cette fonction pour visualiser le nuage des mots de 1gram les plus fr√©quents
# J'ai choisi des s√©quences d'un seul mot (1gram)
n=1
vis_nuage_mots(ngrams_results, 1)

# Fonction pour la visualisation des donn√©es de n_grams et leurs fr√©quence sous forme des barres horizontales .
def plot_ngrams(ngrams_results, n):
    ngrams, frequencies = zip(*ngrams_results[n])
    plt.figure(figsize=(10, 6))
    plt.barh(ngrams, frequencies, color='orange')
    plt.xlabel('Fr√©quence')
    plt.ylabel(f'{n}-gram')
    plt.title(f'{n}-grams les plus fr√©quents')
    plt.gca().invert_yaxis()
    plt.show()
    
# On applique cette fonction pour visualiser les 5grams les plus fr√©quents 
# j'ai choisi s√©quence contient 8 mots 
n=8
plot_ngrams(ngrams_results, 8)





""" 
   Fonction 3  : Remplir un Google Sheets √† partir d'un DataFrame

"""

# Fonction pour mettre √† jour Google Sheets avec un DataFrame
def update_google_sheet(user, spreadsheet_id, sheet_name, dataframe):
    try:
        # Ouvrir le Google Sheet par son ID
        sheet = user.open_by_key(spreadsheet_id)
        worksheet = sheet.worksheet(sheet_name)
        
        # Convertir le DataFrame en liste de listes
        values = [dataframe.columns.values.tolist()] + dataframe.values.tolist()
        worksheet.clear()

        # Mettre √† jour les donn√©es dans Google Sheets √† partir du col A1
        worksheet.update('A1', values)
        
        print("Mettre √† jour de Google Sheets r√©ussie.")
    except Exception as e:
        print(f"Erreur lors de mis √† jour: {e}")




json_url = r'data\config\eskimoz-etude-cas-46017-d740eda083ad.json' 
# Connexion √† l'API Google Sheets
user = connexion_to_googlesheets(json_url)

# Chargement du DataFrame √† partir d'un fichier CSV : data_science_phrases( un exemple )
csv_path = r'data\data_science_phrases.csv'
df = pd.read_csv(csv_path)
print("DataFrame charg√© avec succ√®s.")
print(df.head(10))

# ID du Google Sheets
spreadsheet_id = '1dHjS38Er2VyDM__OGn5AlhnXj1EzlF7QdEYwOVmIH50'
sheet_name = 'myfile' 

# Mettre √† jour le Google Sheets avec les donn√©es du DataFrame
update_google_sheet(user, spreadsheet_id, sheet_name, df)
